{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa164e7-70e4-478d-b996-ff00d141f4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "import mne\n",
    "mne.set_log_level('ERROR')\n",
    "\n",
    "from warnings import filterwarnings\n",
    "filterwarnings('ignore')\n",
    "\n",
    "\n",
    "from IPython.utils import io\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.nn.functional import relu\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "from braindecode import EEGClassifier\n",
    "from braindecode.training.losses import CroppedLoss\n",
    "from braindecode.models import Deep4Net,ShallowFBCSPNet,EEGNetv4, TCN\n",
    "from braindecode.util import set_random_seeds\n",
    "from braindecode.models.util import to_dense_prediction_model, get_output_shape\n",
    "\n",
    "from braindecode.datautil.windowers import create_fixed_length_windows\n",
    "from braindecode.datautil.serialization import  load_concat_dataset\n",
    "\n",
    "from braindecode.datasets import BaseConcatDataset\n",
    "from braindecode.datautil.preprocess import preprocess, Preprocessor, exponential_moving_standardize\n",
    "\n",
    "\n",
    "from braindecode.training import trial_preds_from_window_preds\n",
    "\n",
    "\n",
    "from functools import partial \n",
    "from skorch.callbacks import LRScheduler, EarlyStopping,Checkpoint, EpochScoring\n",
    "from skorch.helper import predefined_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e031240e-10b1-46fc-8457-1b373bea9252",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2cff32-bbe4-4a56-b7ea-ea76cb1c0bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model-specific\n",
    "model_name = 'BD-Deep4'\n",
    "drop_prob=0.5\n",
    "batch_size=64\n",
    "lr=0.01\n",
    "n_epochs=35\n",
    "weight_decay=0.0005\n",
    "\n",
    "# for all models\n",
    "result_folder= '/home/results/TUAB/\n",
    "train_folder='/home/data/preprocessed_TUAB/final_train/'\n",
    "eval_folder= '/home/data/preprocessed_TUAB/final_eval/'\n",
    "task_name = 'train_complete_set'\n",
    "ids_to_load_train=None \n",
    "\n",
    "\n",
    "seed= 20110407\n",
    "\n",
    "\n",
    "\n",
    "n_classes = 2\n",
    "# Extract number of chans from dataset\n",
    "n_chans = 21\n",
    "\n",
    "input_window_samples =6000 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd39682-ef7f-4d24-9f3e-58b97a3fb19f",
   "metadata": {},
   "source": [
    "## Set random seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf35a30-7e4a-421c-a7e2-35f568b887e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.util import set_random_seeds\n",
    "cuda = True\n",
    "# Set random seed to be able to reproduce results\n",
    "set_random_seeds(seed=seed, cuda=cuda)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d92f9-8f56-4d89-bde9-9a34f05a8eaf",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6af52fe-69f8-4c27-8eb4-f594be6633bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as th\n",
    "\n",
    "th.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48197e26-4636-4809-b3e3-08602dafd25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from braindecode.models import Deep4Net,ShallowFBCSPNet,EEGNetv4, TCN\n",
    "\n",
    "\n",
    "\n",
    "## BD-Deep4\n",
    "n_start_chans = 25\n",
    "final_conv_length = 1\n",
    "n_chan_factor = 2\n",
    "stride_before_pool = True\n",
    "model = Deep4Net(\n",
    "            n_chans, n_classes,\n",
    "            n_filters_time=n_start_chans,\n",
    "            n_filters_spat=n_start_chans,\n",
    "            input_window_samples=input_window_samples,\n",
    "            n_filters_2=int(n_start_chans * n_chan_factor),\n",
    "            n_filters_3=int(n_start_chans * (n_chan_factor ** 2.0)),\n",
    "            n_filters_4=int(n_start_chans * (n_chan_factor ** 3.0)),\n",
    "            final_conv_length=final_conv_length,\n",
    "            stride_before_pool=stride_before_pool,\n",
    "            drop_prob=drop_prob)\n",
    "\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "from braindecode.models.util import to_dense_prediction_model, get_output_shape\n",
    "to_dense_prediction_model(model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0453bb41-3d82-494f-b6e6-b027231345a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BD-Shallow\n",
    "n_start_chans = 40\n",
    "final_conv_length = 25\n",
    "\n",
    "model = ShallowFBCSPNet(n_chans,n_classes,\n",
    "                        input_window_samples=input_window_samples,\n",
    "                        n_filters_time=n_start_chans,\n",
    "                        n_filters_spat=n_start_chans,\n",
    "                        final_conv_length= final_conv_length,\n",
    "                        drop_prob=drop_prob)\n",
    "# Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "from braindecode.models.util import to_dense_prediction_model, get_output_shape\n",
    "to_dense_prediction_model(model)\n",
    "\n",
    "n_preds_per_input = get_output_shape(model, n_chans, input_window_samples)[2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c6706fc-0e9a-4fb3-a10b-84f609d63bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BD-TCN\n",
    "\n",
    "n_chan_factor = 2\n",
    "stride_before_pool = True\n",
    "l2_decay = 1.7491630095065614e-08\n",
    "gradient_clip = 0.25\n",
    "\n",
    "model = TCN(\n",
    "    n_in_chans=n_chans, n_outputs=n_classes,\n",
    "    n_filters=55,\n",
    "    n_blocks=5,\n",
    "    kernel_size=16,\n",
    "    drop_prob=drop_prob,\n",
    "    add_log_softmax=True)\n",
    "\n",
    "    # Send model to GPU\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "from braindecode.models.util import to_dense_prediction_model, get_output_shape\n",
    "n_preds_per_input = get_output_shape(model, n_chans, input_window_samples)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342d1e85-9be1-401d-9acc-1bcd8fd1198b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BD-EEGNet\n",
    "\n",
    "final_conv_length=18\n",
    "model = EEGNetv4(\n",
    "    n_chans, n_classes,\n",
    "    input_window_samples=input_window_samples,\n",
    "    final_conv_length=final_conv_length,\n",
    "    drop_prob=drop_prob)\n",
    "if cuda:\n",
    "    model.cuda()\n",
    "    \n",
    "from braindecode.models.util import to_dense_prediction_model, get_output_shape\n",
    "to_dense_prediction_model(model)\n",
    "\n",
    "n_preds_per_input = get_output_shape(model, n_chans, input_window_samples)[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8bc02b-44b9-4b06-8d39-8feb427a376f",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0ee9a6-ef32-42f4-910a-ada40df36654",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "from braindecode.datasets.tuh import TUHAbnormal\n",
    "data_path = '/data/datasets/TUH/EEG/tuh_eeg_abnormal/v2.0.0/edf/'\n",
    "dataset = TUHAbnormal(\n",
    "    path=data_path,\n",
    "    recording_ids=None,  # loads the n chronologically first recordings\n",
    "    target_name=target_name,  # age, gender, pathology\n",
    "    preload=False,\n",
    "    add_physician_reports=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5671137b-09ca-4c80-8931-aad87cf4f871",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from braindecode.datasets import BaseConcatDataset\n",
    "dataset = BaseConcatDataset(dataset.datasets[:n_recordings_to_load])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c0f511-18a5-42c3-9166-e49ce16742e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from braindecode.preprocessing import preprocess, Preprocessor, scale as multiply\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "whole_train_set = dataset.split('train')['True']\n",
    "whole_eval_set = dataset.split('train')['False']\n",
    "\n",
    "short_ch_names = sorted([\n",
    "                'A1', 'A2', 'C3', 'C4', 'Cz', 'F3', 'F4', 'F7', 'F8',\n",
    "                'Fp1', 'Fp2', 'Fz', 'O1', 'O2', 'P3', 'P4', 'Pz', 'T3',\n",
    "                 'T4', 'T5', 'T6'\n",
    "            ])\n",
    "ar_ch_names = sorted([\n",
    "    'EEG A1-REF', 'EEG A2-REF',\n",
    "    'EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF', 'EEG C3-REF',\n",
    "    'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF', 'EEG O2-REF',\n",
    "    'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF', 'EEG T5-REF',\n",
    "    'EEG T6-REF', 'EEG FZ-REF', 'EEG CZ-REF', 'EEG PZ-REF'])\n",
    "le_ch_names = sorted([\n",
    "    'EEG A1-LE', 'EEG A2-LE',\n",
    "    'EEG FP1-LE', 'EEG FP2-LE', 'EEG F3-LE', 'EEG F4-LE', 'EEG C3-LE',\n",
    "    'EEG C4-LE', 'EEG P3-LE', 'EEG P4-LE', 'EEG O1-LE', 'EEG O2-LE',\n",
    "    'EEG F7-LE', 'EEG F8-LE', 'EEG T3-LE', 'EEG T4-LE', 'EEG T5-LE',\n",
    "    'EEG T6-LE', 'EEG FZ-LE', 'EEG CZ-LE', 'EEG PZ-LE'])\n",
    "assert len(short_ch_names) == len(ar_ch_names) == len(le_ch_names)\n",
    "ar_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n",
    "    ar_ch_names, short_ch_names)}\n",
    "le_ch_mapping = {ch_name: short_ch_name for ch_name, short_ch_name in zip(\n",
    "    le_ch_names, short_ch_names)}\n",
    "ch_mapping = {'ar': ar_ch_mapping, 'le': le_ch_mapping}\n",
    "\n",
    "\n",
    "\n",
    "def custom_rename_channels(raw, mapping):\n",
    "    # rename channels which are dependent on referencing:\n",
    "    # le: EEG 01-LE, ar: EEG 01-REF\n",
    "    # mne fails if the mapping contains channels as keys that are not present\n",
    "    # in the raw\n",
    "    reference = raw.ch_names[0].split('-')[-1].lower()\n",
    "    assert reference in ['le', 'ref'], 'unexpected referencing'\n",
    "    reference = 'le' if reference == 'le' else 'ar'\n",
    "    raw.rename_channels(mapping[reference])\n",
    "\n",
    "\n",
    "def custom_crop(raw, tmin=0.0, tmax=None, include_tmax=True):\n",
    "    # crop recordings to tmin – tmax. can be incomplete if recording\n",
    "    # has lower duration than tmax\n",
    "    # by default mne fails if tmax is bigger than duration\n",
    "    tmax = min((raw.n_times - 1) / raw.info['sfreq'], tmax)\n",
    "    raw.crop(tmin=tmin, tmax=tmax, include_tmax=include_tmax)\n",
    "\n",
    "\n",
    "n_max_minutes=21\n",
    "tmin = 1 * 60\n",
    "tmax = n_max_minutes * 60\n",
    "sfreq = 100\n",
    "\n",
    "preprocessors = [\n",
    "    Preprocessor(custom_crop, tmin=tmin, tmax=tmax, include_tmax=False,\n",
    "                 apply_on_array=False),\n",
    "\n",
    "    Preprocessor(custom_rename_channels, mapping=ch_mapping,\n",
    "                 apply_on_array=False),\n",
    "    Preprocessor('pick_channels', ch_names=short_ch_names, ordered=True),\n",
    " \n",
    "    Preprocessor(multiply, factor=1e6, apply_on_array=True),\n",
    "    Preprocessor(np.clip, a_min=-800, a_max=800, apply_on_array=True),\n",
    "    \n",
    "    Preprocessor('set_eeg_reference', ref_channels='average', ch_type='eeg'),\n",
    "\n",
    "    Preprocessor('resample', sfreq=sfreq),\n",
    "    Preprocessor('set_meas_date', meas_date=None)\n",
    "    \n",
    "]\n",
    "# Preprocess the data\n",
    "preprocess(whole_train_set, preprocessors)\n",
    "\n",
    "\n",
    "# OR Preprocess and save dataset\n",
    "preprocess(\n",
    "            concat_ds=whole_train_set,\n",
    "            preprocessors=preprocessors,\n",
    "            n_jobs=4, \n",
    "            save_dir='/home/data/preprocessed_TUAB/final_train/', \n",
    "        )\n",
    "\n",
    "\n",
    "preprocess(\n",
    "            concat_ds=whole_eval_set,\n",
    "            preprocessors=preprocessors,\n",
    "            n_jobs=4, \n",
    "            save_dir='/home/data/preprocessed_TUAB/final_eval/', \n",
    "        )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d04f5793-d6be-4dc3-a2ba-5206fd832796",
   "metadata": {},
   "source": [
    "## OR load preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de3d3e16-f3b0-4fef-aeee-6d079fdcc43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil.serialization import  load_concat_dataset\n",
    "whole_train_set = load_concat_dataset(train_folder, preload=False, ids_to_load=ids_to_load_train)\n",
    "\n",
    "whole_eval_set = load_concat_dataset(eval_folder, preload=False, ids_to_load=ids_to_load_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0875496a-fcbf-4bdc-9df1-dbb5b1196d23",
   "metadata": {},
   "source": [
    "## load smaller subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d63f6f0e-4ced-4aa2-bc6d-321b61f8a61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./indices/TUAB-Random/indices_seed0_TUAB-Random_trainsize_100.pkl\", 'rb') as f:\n",
    "         ids_to_load_train = pickle.load(f) \n",
    "\n",
    "\n",
    "task_name = 'TUAB_subset_' + str(subset_size)\n",
    "\n",
    "whole_train_set = load_concat_dataset(train_folder, preload=False, ids_to_load=ids_to_load_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f67d269-7200-4c19-911b-5b195cd8e7d6",
   "metadata": {},
   "source": [
    "#  Data Compute Window Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "892b6f96-4427-4f1c-bfad-c06848f1437f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from braindecode.models.util import to_dense_prediction_model, get_output_shape\n",
    "\n",
    "n_preds_per_input = get_output_shape(model, n_chans, input_window_samples)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2c7cf7-7244-4380-a1b5-cc3f4d970ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from braindecode.datautil.windowers import create_fixed_length_windows\n",
    "\n",
    "\n",
    "\n",
    "window_train_set = create_fixed_length_windows(whole_train_set, \n",
    "                                                        start_offset_samples=0,\n",
    "                                                        stop_offset_samples=None,\n",
    "                                                        preload=True,\n",
    "                                                        window_size_samples=input_window_samples,\n",
    "                                                        window_stride_samples=n_preds_per_input,\n",
    "                                                        drop_last_window=True,)\n",
    "\n",
    "\n",
    "window_eval_set = create_fixed_length_windows(whole_eval_set,\n",
    "                                            start_offset_samples=0,\n",
    "                                            stop_offset_samples=None,preload=False,\n",
    "                                            window_size_samples=input_window_samples,\n",
    "                                            window_stride_samples=n_preds_per_input,\n",
    "                                            drop_last_window=False,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6664462c-6df9-46b7-a6ed-41db5b8c3e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Classifier definition and run training\n",
    "\n",
    "clf = EEGClassifier(model,cropped=True,\n",
    "                    criterion=CroppedLoss,\n",
    "                    criterion__loss_function=torch.nn.functional.nll_loss,\n",
    "                    optimizer=torch.optim.AdamW,\n",
    "                    train_split=predefined_split(window_eval_set),\n",
    "                    optimizer__lr=lr,\n",
    "                    optimizer__weight_decay=weight_decay,\n",
    "                    iterator_train__shuffle=True,\n",
    "                    batch_size=batch_size,\n",
    "                    callbacks=[\"accuracy\",(\"lr_scheduler\", LRScheduler('CosineAnnealingLR', T_max=n_epochs - 1)),],  #\"accuracy\",\n",
    "                    device='cuda')\n",
    "\n",
    "\n",
    "clf.fit(window_train_set, y=None, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbaabc3-3b3c-486f-9dd2-42819d7b26a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save trained classifer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611d6c1f-3169-4fc6-8a90-ddcc98894120",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(clf.history[:, results_columns], columns=results_columns,index=clf.history[:, 'epoch'])\n",
    "df.to_pickle(result_path + '_df_history.pkl')\n",
    "#save history\n",
    "torch.save(clf.history, result_path + '_clf_history.py')\n",
    "\n",
    "path = result_path + \"model_{}.pt\".format(seed)\n",
    "torch.save(clf.module, path)\n",
    "path = result_path + \"state_dict_{}.pt\".format(seed)\n",
    "torch.save(clf.module.state_dict(), path)\n",
    "\n",
    "clf.save_params(f_params=result_path +'model.pkl', f_optimizer= result_path +'opt.pkl', f_history=result_path +'history.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75d1219-cca8-4503-921e-5d9b8aee82fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate performance test set and save prediction results\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from braindecode.training import trial_preds_from_window_preds\n",
    "\n",
    "\n",
    "pred_win = clf.predict_with_window_inds_and_ys(window_eval_set)\n",
    "\n",
    "\n",
    "\n",
    "preds_per_trial= trial_preds_from_window_preds(pred_win['preds'], pred_win['i_window_in_trials'], pred_win['i_window_stops'])\n",
    "mean_preds_per_trial = [np.mean(preds, axis=1) for preds in\n",
    "                                preds_per_trial]\n",
    "mean_preds_per_trial = np.array(mean_preds_per_trial)\n",
    "y = window_eval_set.description['pathological']\n",
    "column0, column1 = \"non-pathological\", \"pathological\"\n",
    "a_dict = {column0: mean_preds_per_trial[:, 0],\n",
    "          column1: mean_preds_per_trial[:, 1],\n",
    "          \"true_pathological\": y}\n",
    "\n",
    "assert len(y) == len(mean_preds_per_trial)\n",
    "\n",
    "# store predictions\n",
    "pd.DataFrame.from_dict(a_dict).to_csv(result_path + \"predictions_eval_\" + str(model_number) +\n",
    "                                          \".csv\")\n",
    "\n",
    "deep_preds =  mean_preds_per_trial[:, 0] <=  mean_preds_per_trial[:, 1]\n",
    "class_label = window_eval_set.description['pathological']\n",
    "class_preds =deep_preds.astype(int)\n",
    "\n",
    "\n",
    "    \n",
    "from sklearn.metrics import confusion_matrix    \n",
    "confusion_mat = confusion_matrix(class_label, class_preds)\n",
    "\n",
    "print(classification_report(class_label, class_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
